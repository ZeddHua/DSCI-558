{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "juvenile-butterfly",
   "metadata": {
    "id": "K8fyiwzJJ3xP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 1-1. Construct RLTK Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fuzzy-financing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:53:13.554165Z",
     "iopub.status.busy": "2022-09-20T03:53:13.554165Z",
     "iopub.status.idle": "2022-09-20T03:53:14.824880Z",
     "shell.execute_reply": "2022-09-20T03:53:14.824880Z",
     "shell.execute_reply.started": "2022-09-20T03:53:13.554165Z"
    }
   },
   "outputs": [],
   "source": [
    "import rltk\n",
    "import csv\n",
    "\n",
    "# You can use this tokenizer in case you need to manipulate some data\n",
    "tokenizer = rltk.tokenizer.crf_tokenizer.crf_tokenizer.CrfTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "threatened-munich",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:53:14.825885Z",
     "iopub.status.busy": "2022-09-20T03:53:14.825885Z",
     "iopub.status.idle": "2022-09-20T03:53:14.840846Z",
     "shell.execute_reply": "2022-09-20T03:53:14.840846Z",
     "shell.execute_reply.started": "2022-09-20T03:53:14.825885Z"
    }
   },
   "outputs": [],
   "source": [
    "class GoodRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def Title(self):\n",
    "        return self.raw_object['Title']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def ISBN(self):\n",
    "        return self.raw_object['ISBN13']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def Author(self):\n",
    "        return self.raw_object['FirstAuthor']\n",
    "\n",
    "class NobleRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def Title(self):\n",
    "        return self.raw_object['Title']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def ISBN(self):\n",
    "        return self.raw_object['ISBN13']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def Author(self):\n",
    "        return self.raw_object['Author1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aggressive-elephant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:53:15.243158Z",
     "iopub.status.busy": "2022-09-20T03:53:15.243158Z",
     "iopub.status.idle": "2022-09-20T03:53:15.408815Z",
     "shell.execute_reply": "2022-09-20T03:53:15.407828Z",
     "shell.execute_reply.started": "2022-09-20T03:53:15.243158Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_ = ''\n",
    "good_file = dir_ + 'goodreads.csv'\n",
    "noble_file = dir_ + 'barnes_and_nobles.csv'\n",
    "\n",
    "ds1 = rltk.Dataset(rltk.CSVReader(open(good_file, encoding='utf-8')), record_class=GoodRecord)\n",
    "ds2 = rltk.Dataset(rltk.CSVReader(open(noble_file, encoding='utf-8')), record_class=NobleRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "statutory-telling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:53:15.922947Z",
     "iopub.status.busy": "2022-09-20T03:53:15.922947Z",
     "iopub.status.idle": "2022-09-20T03:53:15.961876Z",
     "shell.execute_reply": "2022-09-20T03:53:15.961876Z",
     "shell.execute_reply.started": "2022-09-20T03:53:15.922947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id                                       Title           ISBN  \\\n",
      "0  0          Managing My Life: My Autobiography  9780340728567   \n",
      "1  1     I Remember: Sketch for an Autobiography  9780844627106   \n",
      "2  2              Betty Boothroyd: Autobiography  9780712679480   \n",
      "3  3  Caddie, A Sydney Barmaid: An Autobiography  9780725100148   \n",
      "4  4     Nureyev: An Autobiography With Pictures  9780340014684   \n",
      "\n",
      "            Author  \n",
      "0    Alex Ferguson  \n",
      "1  Boris Pasternak  \n",
      "2  Betty Boothroyd  \n",
      "3           Caddie  \n",
      "4   Rudolf Nureyev  \n",
      "  id                                              Title           ISBN  \\\n",
      "0  0          Pioneer Girl: The Annotated Autobiography  9780984504176   \n",
      "1  1  American Sniper (Movie Tie-in Edition): The Au...  9780062376336   \n",
      "2  2                     The Autobiography of Malcolm X  9780345350688   \n",
      "3  3                           Assata: An Autobiography  9781556520747   \n",
      "4  4                            Autobiography of a Yogi  9780876120798   \n",
      "\n",
      "                  Author  \n",
      "0   Laura Ingalls Wilder  \n",
      "1             Chris Kyle  \n",
      "2              Malcolm X  \n",
      "3          Assata Shakur  \n",
      "4  Paramahansa Yogananda  \n"
     ]
    }
   ],
   "source": [
    "# print some entries\n",
    "print(ds1.generate_dataframe().head(5))\n",
    "print(ds2.generate_dataframe().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-frame",
   "metadata": {
    "id": "MB0HHqDpJ3xR"
   },
   "source": [
    "### Task 1-2. Blocking\n",
    "\n",
    "First, we'll load dev set to evaluate both blocking (Task 1-2) and entity linking (Task 1-3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "combined-somalia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:53:21.143772Z",
     "iopub.status.busy": "2022-09-20T03:53:21.143772Z",
     "iopub.status.idle": "2022-09-20T03:53:21.163719Z",
     "shell.execute_reply": "2022-09-20T03:53:21.163719Z",
     "shell.execute_reply.started": "2022-09-20T03:53:21.143772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are: goodreads.ID, barnes_and_nobles.ID, label\n",
      "Processed 297 lines.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rltk.evaluation.trial.Trial at 0x20f0b5c2130>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set_file = dir_ + 'dev.csv'\n",
    "dev = []\n",
    "with open(dev_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if len(row) <= 1:\n",
    "            continue\n",
    "        if line_count == 0:\n",
    "            columns = row\n",
    "            line_count += 1\n",
    "        else:\n",
    "            dev.append(row)\n",
    "    print(f'Column names are: {\", \".join(columns)}')\n",
    "    print(f'Processed {len(dev)} lines.')\n",
    "\n",
    "gt = rltk.GroundTruth()\n",
    "for row in dev:    \n",
    "    r1 = ds1.get_record(row[0])\n",
    "    r2  = ds2.get_record(row[1])\n",
    "    if row[-1] == '1':\n",
    "        gt.add_positive(r1.raw_object['ID'], r2.raw_object['ID'])\n",
    "    else:\n",
    "        gt.add_negative(r1.raw_object['ID'], r2.raw_object['ID'])\n",
    "\n",
    "rltk.Trial(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-greece",
   "metadata": {
    "id": "aJ07ud86J3xR"
   },
   "source": [
    "Then, you can build your own blocking techniques and evaluate it.\n",
    "\n",
    "Hint:\n",
    "\n",
    "- What is the total number of pairs without blocking? \n",
    "- what is the number of paris with blocking?\n",
    "- After blocking, how many \"correct\" (matched) pairs presented in dev set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "korean-insured",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T04:00:49.104048Z",
     "iopub.status.busy": "2022-09-20T04:00:49.104048Z",
     "iopub.status.idle": "2022-09-20T04:00:55.822009Z",
     "shell.execute_reply": "2022-09-20T04:00:55.821008Z",
     "shell.execute_reply.started": "2022-09-20T04:00:49.104048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ No Blocks ------\n",
      "There are 14681867 pairs without blocking.\n",
      "------ block on Title ------\n",
      "0 Managing My Life: My Autobiography \t 409 Managing My Life: My Autobiography\n",
      "8 Jenny Pitman: The Autobiography \t 1431 Jenny Pitman: The Autobiography\n",
      "11 Call Me Anna: The Autobiography of Patty Duke \t 100 Call Me Anna: The Autobiography of Patty Duke\n",
      "13 Chasing the Wind: The Autobiography of Steve Fossett \t 1152 Chasing the Wind: The Autobiography of Steve Fossett\n",
      "22 Mad, Bad & Dangerous to Know: The Autobiography \t 192 Mad, Bad & Dangerous to Know: The Autobiography\n",
      "There are 3484 pairs with blocking.\n",
      "There are 40 matched pairs presented in dev set.\n",
      "reduction_ratio: 0.00023729952055825054\n",
      "pairs_completeness: 0.5970149253731343\n",
      "pair_quality: 0.011481056257175661\n",
      "------ block on Title[:3] ------\n",
      "194 Man: An Autobiography \t 2625 Man Without A Face / Edition 1\n",
      "194 Man: An Autobiography \t 1161 Man Of Everest - The Autobiography Of Tenzing\n",
      "194 Man: An Autobiography \t 377 Man Who Lives in Paradise: Autobiography of A. C. Gilbert with Marshall McClintock\n",
      "194 Man: An Autobiography \t 1887 Man and Woman, War and Peace 1941-1951: A Dual Autobiography\n",
      "194 Man: An Autobiography \t 3568 Man Who Tried: An Autobiography\n",
      "There are 759133 pairs with blocking.\n",
      "There are 63 matched pairs presented in dev set.\n",
      "reduction_ratio: 0.05170548132604661\n",
      "pairs_completeness: 0.9402985074626866\n",
      "pair_quality: 8.298941028778884e-05\n",
      "------ block on ISBN13 ------\n",
      "0 Managing My Life: My Autobiography 9780340728567 \t 409 Managing My Life: My Autobiography 9780340728567\n",
      "10 A Man Called White: The Autobiography of Walter White 9780820316987 \t 769 A Man Called White: The Autobiography of Walter White / Edition 1 9780820316987\n",
      "291 Bertolt Brecht: A Literary Life (Biography and Autobiography)   \t 1315 Recovering Literature's Lost Ground: Essays in American Autobiography  \n",
      "649 Against The Evil Tide - An Autobiography   \t 1315 Recovering Literature's Lost Ground: Essays in American Autobiography  \n",
      "2676 Autobiography of Andrew T. Still   \t 1315 Recovering Literature's Lost Ground: Essays in American Autobiography  \n",
      "There are 1239 pairs with blocking.\n",
      "There are 37 matched pairs presented in dev set.\n",
      "reduction_ratio: 8.438981227659942e-05\n",
      "pairs_completeness: 0.5522388059701493\n",
      "pair_quality: 0.02986279257465698\n",
      "------ block on Title[:3] + 1st Author[:3] ------\n",
      "2 Betty Boothroyd: Autobiography \t 2851 Betty: The Autobiography\n",
      "2 Betty Boothroyd: Autobiography \t 2541 Betty Boothroyd Autobiography\n",
      "559 Betty: The Autobiography \t 2851 Betty: The Autobiography\n",
      "559 Betty: The Autobiography \t 2541 Betty Boothroyd Autobiography\n",
      "563 Betty: The Autobiography \t 2851 Betty: The Autobiography\n",
      "There are 9543 pairs with blocking.\n",
      "There are 54 matched pairs presented in dev set.\n",
      "reduction_ratio: 0.0006499854548471254\n",
      "pairs_completeness: 0.8059701492537313\n",
      "pair_quality: 0.005658597925180761\n",
      "------ block on Title[:5] + 1st Author[:5] ------\n",
      "2 Betty Boothroyd: Autobiography \t 2851 Betty: The Autobiography\n",
      "2 Betty Boothroyd: Autobiography \t 2541 Betty Boothroyd Autobiography\n",
      "559 Betty: The Autobiography \t 2851 Betty: The Autobiography\n",
      "559 Betty: The Autobiography \t 2541 Betty Boothroyd Autobiography\n",
      "563 Betty: The Autobiography \t 2851 Betty: The Autobiography\n",
      "There are 4019 pairs with blocking.\n",
      "There are 53 matched pairs presented in dev set.\n",
      "reduction_ratio: 0.0002737390278770404\n",
      "pairs_completeness: 0.7910447761194029\n",
      "pair_quality: 0.013187360039810898\n"
     ]
    }
   ],
   "source": [
    "correct_pairs = list(map(lambda x: (x[0], x[1]), filter(lambda x: x[2] == '1', dev)))\n",
    "\n",
    "print('------ No Blocks ------')\n",
    "pairs_without_blocking = rltk.get_record_pairs(ds1, ds2)\n",
    "num_0 = 0\n",
    "for r1, r2 in pairs_without_blocking:\n",
    "    num_0 += 1\n",
    "print(f'There are {num_0} pairs without blocking.')\n",
    "\n",
    "\n",
    "print('------ block on Title ------')\n",
    "bg = rltk.HashBlockGenerator()\n",
    "block = bg.generate(bg.block(ds1, property_='Title'),\n",
    "                    bg.block(ds2, property_='Title'))\n",
    "pairs = rltk.get_record_pairs(ds1, ds2, block=block)\n",
    "num = 0\n",
    "matched_pairs_num = 0\n",
    "for r1, r2 in pairs:\n",
    "    num += 1\n",
    "    if (r1.id, r2.id) in correct_pairs:\n",
    "        matched_pairs_num += 1\n",
    "    if num <= 5:\n",
    "        print(r1.id, r1.Title, '\\t', r2.id, r2.Title)\n",
    "print(f'There are {num} pairs with blocking.')\n",
    "print(f'There are {matched_pairs_num} matched pairs presented in dev set.')\n",
    "reduction_ratio = num / num_0\n",
    "pairs_completeness = matched_pairs_num / len(correct_pairs)\n",
    "pair_quality = matched_pairs_num / num\n",
    "print(f'reduction_ratio: {reduction_ratio}')\n",
    "print(f'pairs_completeness: {pairs_completeness}')\n",
    "print(f'pair_quality: {pair_quality}')\n",
    "\n",
    "\n",
    "print('------ block on Title[:3] ------')\n",
    "bg2 = rltk.HashBlockGenerator()\n",
    "block2 = bg2.generate(\n",
    "            bg2.block(ds1, function_=lambda r: r.Title[:3]),\n",
    "            bg2.block(ds2, function_=lambda r: r.Title[:3]))\n",
    "pairs = rltk.get_record_pairs(ds1, ds2, block=block2)\n",
    "num = 0\n",
    "matched_pairs_num = 0\n",
    "for r1, r2 in pairs:\n",
    "    num += 1\n",
    "    if (r1.id, r2.id) in correct_pairs:\n",
    "        matched_pairs_num += 1\n",
    "    if num <= 5:\n",
    "        print(r1.id, r1.Title, '\\t', r2.id, r2.Title)\n",
    "print(f'There are {num} pairs with blocking.')\n",
    "print(f'There are {matched_pairs_num} matched pairs presented in dev set.')\n",
    "reduction_ratio = num / num_0\n",
    "pairs_completeness = matched_pairs_num / len(correct_pairs)\n",
    "pair_quality = matched_pairs_num / num\n",
    "print(f'reduction_ratio: {reduction_ratio}')\n",
    "print(f'pairs_completeness: {pairs_completeness}')\n",
    "print(f'pair_quality: {pair_quality}')\n",
    "\n",
    "\n",
    "print('------ block on ISBN13 ------')\n",
    "bg3 = rltk.HashBlockGenerator()\n",
    "block3 = bg3.generate(\n",
    "            bg3.block(ds1, property_='ISBN'),\n",
    "            bg3.block(ds2, property_='ISBN'))\n",
    "pairs = rltk.get_record_pairs(ds1, ds2, block=block3)\n",
    "num = 0\n",
    "matched_pairs_num = 0\n",
    "for r1, r2 in pairs:\n",
    "    num += 1\n",
    "    if (r1.id, r2.id) in correct_pairs:\n",
    "        matched_pairs_num += 1\n",
    "    if num <= 5:\n",
    "        print(r1.id, r1.Title, r1.ISBN, '\\t', r2.id, r2.Title, r2.ISBN)\n",
    "print(f'There are {num} pairs with blocking.')\n",
    "print(f'There are {matched_pairs_num} matched pairs presented in dev set.')\n",
    "reduction_ratio = num / num_0\n",
    "pairs_completeness = matched_pairs_num / len(correct_pairs)\n",
    "pair_quality = matched_pairs_num / num\n",
    "print(f'reduction_ratio: {reduction_ratio}')\n",
    "print(f'pairs_completeness: {pairs_completeness}')\n",
    "print(f'pair_quality: {pair_quality}')\n",
    "\n",
    "\n",
    "print('------ block on Title[:3] + 1st Author[:3] ------')\n",
    "bg4 = rltk.HashBlockGenerator()\n",
    "block4 = bg4.generate(\n",
    "            bg4.block(ds1, function_=lambda r: r.Title[:3] + r.Author[:3]),\n",
    "            bg4.block(ds2, function_=lambda r: r.Title[:3] + r.Author[:3]))\n",
    "pairs = rltk.get_record_pairs(ds1, ds2, block=block4)\n",
    "num = 0\n",
    "matched_pairs_num = 0\n",
    "for r1, r2 in pairs:\n",
    "    num += 1\n",
    "    if (r1.id, r2.id) in correct_pairs:\n",
    "        matched_pairs_num += 1\n",
    "    if num <= 5:\n",
    "        print(r1.id, r1.Title, '\\t', r2.id, r2.Title)\n",
    "print(f'There are {num} pairs with blocking.')\n",
    "print(f'There are {matched_pairs_num} matched pairs presented in dev set.')\n",
    "reduction_ratio = num / num_0\n",
    "pairs_completeness = matched_pairs_num / len(correct_pairs)\n",
    "pair_quality = matched_pairs_num / num\n",
    "print(f'reduction_ratio: {reduction_ratio}')\n",
    "print(f'pairs_completeness: {pairs_completeness}')\n",
    "print(f'pair_quality: {pair_quality}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-plaintiff",
   "metadata": {},
   "source": [
    "**block4's performance is better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "handy-treat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:16.197596Z",
     "iopub.status.busy": "2022-09-20T03:55:16.197596Z",
     "iopub.status.idle": "2022-09-20T03:55:16.242476Z",
     "shell.execute_reply": "2022-09-20T03:55:16.241477Z",
     "shell.execute_reply.started": "2022-09-20T03:55:16.197596Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs = rltk.get_record_pairs(ds1, ds2, block=block4)\n",
    "blocked_pairs = []\n",
    "for r1, r2 in pairs:\n",
    "    blocked_pairs.append((r1.id, r2.id))\n",
    "\n",
    "with open(dir_ + 'Zhenmin_Hua_blocked.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    header = ['goodreads.ID', 'barnes_and_nobles.ID']\n",
    "    writer.writerow(header)\n",
    "    for row in blocked_pairs:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-sigma",
   "metadata": {
    "id": "OCpi3AqZJ3xR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 1-3. Entity Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spare-triple",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:28.275413Z",
     "iopub.status.busy": "2022-09-20T03:55:28.274415Z",
     "iopub.status.idle": "2022-09-20T03:55:28.290372Z",
     "shell.execute_reply": "2022-09-20T03:55:28.290372Z",
     "shell.execute_reply.started": "2022-09-20T03:55:28.275413Z"
    }
   },
   "outputs": [],
   "source": [
    "def name_string_similarity_1(r1, r2):\n",
    "    s1 = r1.Title\n",
    "    s2 = r2.Title\n",
    "    return rltk.jaro_winkler_similarity(s1, s2)\n",
    "    \n",
    "def name_string_similarity_2(r1, r2):\n",
    "    s1 = r1.ISBN\n",
    "    s2 = r2.ISBN\n",
    "    if s1 == s2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def name_string_similarity_3(r1, r2):\n",
    "    for n1, n2 in zip(sorted(r1.Title), sorted(r2.Title)):\n",
    "        if rltk.levenshtein_distance(n1, n2) > min(len(n1), len(n2)) / 3:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fourth-orleans",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:32.316656Z",
     "iopub.status.busy": "2022-09-20T03:55:32.315658Z",
     "iopub.status.idle": "2022-09-20T03:55:32.331613Z",
     "shell.execute_reply": "2022-09-20T03:55:32.331613Z",
     "shell.execute_reply.started": "2022-09-20T03:55:32.316656Z"
    }
   },
   "outputs": [],
   "source": [
    "# threshold value to determine if we are confident the record match\n",
    "MY_TRESH = 0.8\n",
    "\n",
    "# entity linkage scoring function\n",
    "def rule_based_method(r1, r2):\n",
    "    score_1 = name_string_similarity_1(r1, r2)\n",
    "    score_2 = name_string_similarity_2(r1, r2)\n",
    "    score_3 = name_string_similarity_3(r1, r2)\n",
    "    \n",
    "    total = 0.8 * score_1 + 0.1 * score_2 + 0.1 * score_3\n",
    "    \n",
    "    # return two values: boolean if they match or not, float to determine confidence\n",
    "    return total > MY_TRESH, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "controlling-forge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:32.746055Z",
     "iopub.status.busy": "2022-09-20T03:55:32.746055Z",
     "iopub.status.idle": "2022-09-20T03:55:32.832881Z",
     "shell.execute_reply": "2022-09-20T03:55:32.832881Z",
     "shell.execute_reply.started": "2022-09-20T03:55:32.746055Z"
    }
   },
   "outputs": [],
   "source": [
    "trial = rltk.Trial(gt)\n",
    "candidate_pairs = rltk.get_record_pairs(ds1, ds2, ground_truth=gt)\n",
    "for r1, r2 in candidate_pairs:\n",
    "    result, confidence = rule_based_method(r1, r2)\n",
    "    trial.add_result(r1, r2, result, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "spatial-sympathy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:33.266022Z",
     "iopub.status.busy": "2022-09-20T03:55:33.265025Z",
     "iopub.status.idle": "2022-09-20T03:55:33.277017Z",
     "shell.execute_reply": "2022-09-20T03:55:33.277017Z",
     "shell.execute_reply.started": "2022-09-20T03:55:33.266022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial statistics based on Ground-Truth from development set data:\n",
      "tp: 0.835821 [56]\n",
      "fp: 0.056522 [13]\n",
      "tn: 0.943478 [217]\n",
      "fn: 0.164179 [11]\n"
     ]
    }
   ],
   "source": [
    "trial.evaluate()\n",
    "print('Trial statistics based on Ground-Truth from development set data:')\n",
    "print(f'tp: {trial.true_positives:.06f} [{len(trial.true_positives_list)}]')\n",
    "print(f'fp: {trial.false_positives:.06f} [{len(trial.false_positives_list)}]')\n",
    "print(f'tn: {trial.true_negatives:.06f} [{len(trial.true_negatives_list)}]')\n",
    "print(f'fn: {trial.false_negatives:.06f} [{len(trial.false_negatives_list)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "accomplished-atlanta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:34.744615Z",
     "iopub.status.busy": "2022-09-20T03:55:34.743616Z",
     "iopub.status.idle": "2022-09-20T03:55:34.759425Z",
     "shell.execute_reply": "2022-09-20T03:55:34.758452Z",
     "shell.execute_reply.started": "2022-09-20T03:55:34.744615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823529411764706"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.f_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-suicide",
   "metadata": {
    "id": "32c-kCWqJ3xT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save Test predictions\n",
    "You will be evaluated on dev and test predictions, over a hidden ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "actual-interest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:42.052492Z",
     "iopub.status.busy": "2022-09-20T03:55:42.052492Z",
     "iopub.status.idle": "2022-09-20T03:55:42.068450Z",
     "shell.execute_reply": "2022-09-20T03:55:42.067454Z",
     "shell.execute_reply.started": "2022-09-20T03:55:42.052492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are: goodreads.ID, barnes_and_nobles.ID\n",
      "Processed 90 lines.\n"
     ]
    }
   ],
   "source": [
    "test_set_file = dir_ + 'test.csv'\n",
    "test = []\n",
    "with open(test_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if len(row) <= 1:\n",
    "            continue\n",
    "        if line_count == 0:\n",
    "            columns = row\n",
    "            line_count += 1\n",
    "        else:\n",
    "            test.append(row)\n",
    "    print(f'Column names are: {\", \".join(columns)}')\n",
    "    print(f'Processed {len(test)} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "played-ranking",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:51.504312Z",
     "iopub.status.busy": "2022-09-20T03:55:51.504312Z",
     "iopub.status.idle": "2022-09-20T03:55:51.537223Z",
     "shell.execute_reply": "2022-09-20T03:55:51.537223Z",
     "shell.execute_reply.started": "2022-09-20T03:55:51.504312Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for id1, id2 in test:\n",
    "    r1 = ds1.get_record(id1)\n",
    "    r2 = ds2.get_record(id2)\n",
    "    result, confidence = rule_based_method(r1, r2)\n",
    "    predictions.append((r1.id, r2.id, result, confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "alive-bedroom",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:51.907235Z",
     "iopub.status.busy": "2022-09-20T03:55:51.907235Z",
     "iopub.status.idle": "2022-09-20T03:55:51.947126Z",
     "shell.execute_reply": "2022-09-20T03:55:51.947126Z",
     "shell.execute_reply.started": "2022-09-20T03:55:51.907235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 3967, 3701)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(ds1.generate_dataframe()), len(ds2.generate_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "leading-ivory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T03:55:53.368442Z",
     "iopub.status.busy": "2022-09-20T03:55:53.367443Z",
     "iopub.status.idle": "2022-09-20T03:55:53.385426Z",
     "shell.execute_reply": "2022-09-20T03:55:53.385426Z",
     "shell.execute_reply.started": "2022-09-20T03:55:53.368442Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(dir_ + 'Zhenmin_Hua_predictions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row in predictions:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-chancellor",
   "metadata": {
    "id": "OCpi3AqZJ3xR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 1-4. Record Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "stainless-greene",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T04:07:06.010647Z",
     "iopub.status.busy": "2022-09-20T04:07:06.009650Z",
     "iopub.status.idle": "2022-09-20T04:07:07.316088Z",
     "shell.execute_reply": "2022-09-20T04:07:07.315253Z",
     "shell.execute_reply.started": "2022-09-20T04:07:06.010647Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "matching_pairs = []\n",
    "for r1, r2 in rltk.get_record_pairs(ds1, ds2, block=block4):\n",
    "    result, confidence = rule_based_method(r1, r2)\n",
    "    if result:\n",
    "        i += 1\n",
    "        matching_pairs.append((r1.id, r2.id))\n",
    "\n",
    "with open(dir_ + 'Zhenmin_Hua_valid_predictions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    header = ['goodreads.ID', 'barnes_and_nobles.ID']\n",
    "    writer.writerow(header)\n",
    "    for row in matching_pairs:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-russian",
   "metadata": {
    "id": "G7svOwNGJ3xT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 2: Using RDFLib for Knowledge Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efficient-wisconsin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T21:07:40.831670Z",
     "iopub.status.busy": "2022-09-19T21:07:40.831670Z",
     "iopub.status.idle": "2022-09-19T21:07:41.116724Z",
     "shell.execute_reply": "2022-09-19T21:07:41.116724Z",
     "shell.execute_reply.started": "2022-09-19T21:07:40.831670Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, XSD, Namespace, RDF\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "twenty-genome",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T04:08:55.049970Z",
     "iopub.status.busy": "2022-09-20T04:08:55.049970Z",
     "iopub.status.idle": "2022-09-20T04:08:55.130273Z",
     "shell.execute_reply": "2022-09-20T04:08:55.129320Z",
     "shell.execute_reply.started": "2022-09-20T04:08:55.049970Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('goodreads.csv')\n",
    "df2 = pd.read_csv('barnes_and_nobles.csv')\n",
    "df = pd.read_csv('Zhenmin_Hua_valid_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "vital-football",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T04:08:58.263726Z",
     "iopub.status.busy": "2022-09-20T04:08:58.263726Z",
     "iopub.status.idle": "2022-09-20T04:08:58.431066Z",
     "shell.execute_reply": "2022-09-20T04:08:58.430058Z",
     "shell.execute_reply.started": "2022-09-20T04:08:58.263726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N551d17599e8c412380835e77877e55e0 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYNS = Namespace('http://inf558.org/myfakenamespace#')\n",
    "FOAF = Namespace('http://xmlns.com/foaf/0.1/')\n",
    "SCHEMA = Namespace('http://schema.org/')\n",
    "\n",
    "kg = Graph()\n",
    "kg.bind('my_ns', MYNS)\n",
    "kg.bind('foaf', FOAF)\n",
    "kg.bind('schema', SCHEMA)\n",
    "\n",
    "for i in range(100):    # len(df)\n",
    "    gr_id = df['goodreads.ID'][i]\n",
    "    bn_id = df['barnes_and_nobles.ID'][i]\n",
    "    \n",
    "    item_id = URIRef(str(gr_id))  # subject\n",
    "    kg.add((item_id, RDF.type, MYNS['book']))\n",
    "    kg.add((item_id, FOAF['name'], Literal(df1['Title'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.description, Literal(df1['Description'][gr_id])))\n",
    "    kg.add((item_id, MYNS.ISBN, Literal(df1['ISBN'][gr_id])))\n",
    "    kg.add((item_id, MYNS.ISBN13, Literal(df1['ISBN13'][gr_id])))\n",
    "    kg.add((item_id, MYNS.pageCount, Literal(df1['PageCount'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.author, Literal(df1['FirstAuthor'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.author, Literal(df1['SecondAuthor'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.author, Literal(df1['ThirdAuthor'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.contentRating, Literal(df1['Rating'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.contentRating, Literal(df1['NumberofRatings'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.review, Literal(df1['NumberofReviews'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.publisher, Literal(df1['Publisher'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.datePublished, Literal(df1['PublishDate'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.encodingFormat, Literal(df1['Format'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.inLanguage, Literal(df1['Language'][gr_id])))\n",
    "    kg.add((item_id, SCHEMA.name, Literal(df1['FileName'][gr_id])))\n",
    "           \n",
    "    kg.add((item_id, MYNS.pages, Literal(df2['Pages'][bn_id])))\n",
    "    kg.add((item_id, MYNS.dimensions, Literal(df2['Productdimensions'][bn_id])))\n",
    "    kg.add((item_id, MYNS.Salesrank, Literal(df2['Salesrank'][bn_id])))\n",
    "    kg.add((item_id, SCHEMA.contentRating, Literal(df2['Ratingvalue'][bn_id])))\n",
    "    kg.add((item_id, MYNS.Paperbackprice, Literal(df2['Paperbackprice'][bn_id])))\n",
    "    kg.add((item_id, MYNS.Hardcoverprice, Literal(df2['Hardcoverprice'][bn_id])))\n",
    "    kg.add((item_id, MYNS.Nookbookprice, Literal(df2['Nookbookprice'][bn_id])))\n",
    "    kg.add((item_id, MYNS.Audiobookprice, Literal(df2['Audiobookprice'][bn_id])))\n",
    "           \n",
    "kg.serialize('Zhenmin_Hua_model.ttl', format=\"turtle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
